<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags-->
    <meta name="author" content="Tom Hackshaw">
    <link rel="icon" href="favicon.ico">

    <title>easywork.today</title>

    <!-- Custom CSS -->
    <link href="style.css" rel="stylesheet">
    <link href="featherlight.css" rel="stylesheet">
</head>

<body id="homepage" class="witnessing">
    <outer-container>
        <inner-container>
            <!-- Human Memory Database -->
            <div class="icon glitch example-three">
                <a class="pictures-icon" href="pictures.html">pictures</a>
            </div>
            <!-- you.got.a.pic -->
            <div class="icon glitch example-three">
                <a class="videos-icon" href="videos.html">videos</a>
            </div>
            <!-- Sentinel -->
            <div class="icon glitch example-three">
                <a class="recordings-icon" href="recordings.html">recordings</a>
            </div>
            <!-- readme -->
            <div class="icon glitch example-three">
                <a class="readme-icon" href="#" data-featherlight="#lightbox" data-featherlight-variant="custom-lightbox glitch-child glitch-child-1">easywork.txt</a>
                <a class="readme-icon" href="#" data-featherlight="#lightbox" data-featherlight-variant="custom-lightbox glitch-child glitch-child-2">easywork.txt</a>
                <a class="readme-icon" href="#" data-featherlight="#lightbox" data-featherlight-variant="custom-lightbox glitch-child glitch-child-3">easywork.txt</a>
                <div class="hidden-lightbox lightbox-content" id="lightbox">
                    <h2>easywork.txt</h2>
                    <p>Conceived of as a response to the 2016 exhibit <a href="http://newmediagallery.ca/current-exhibition-2/" target="_blank">“Witness” at New Westminster’s New Media Gallery</a> (Joyce and Duggan 2016), this project, “Witnessing” is a
                        series of three projects developed by students at <a href="http://www.sfu.ca/siat.html" target="_blank">Simon Fraser University’s School of Interactive Art and Technology (SIAT)</a>.</p>

                    <p>The projects all address the thematic issues raised in the Witness exhibit, that of human machine communication and mutual surveillance. Each work presented here demonstrates the uneasy marriage of our shared technological fears and
                        desires. Paired with this web archive, the downloadable Zine is imagined as a future archive of humanities’attempts to communicate with an all-seeing machine. The Zine includes the analog counter-parts to the digital projects,
                        and encourages the reader to contemplate how future machine might learn of our thoughts, memories, languages, and visions.</p>

                    <p>The 2016 “Witness” exhibit showed five works of electronic or media art that all addressed the powerful and potentially omniscient gaze of machines. Adam Basanta’s work, “A Truly Magical Moment” (2016) displays two cell phones affixed
                        to cell phone sticks that spin around each other when called, so each caller experiences the other through multiple and disorienting lenses. Rafael Lozano-Hemmer’s “Surface Tension” (1992 (2001)), uses an infra-red camera mounted
                        above the gallery to monitor visitor movements – all translated to a video screen displaying an eye that follows the viewer as they move through the space. This watchful eye demands the viewer’s full attention, and its’ mechanistic
                        movement and human-like appearance cause us to question our own cyborg realities. France Cadet’s “Do Robotic Cats Dream of Electric Fish?” takes us to a future where cyborg cats do exist, as the hacked robot cat appears to watch
                        an impossible-to-catch electronic fish swimming on screen. Bjorn Schulke’s “Vision Machine” (2014) presents an alternative view of vision and watchfulness as the computerized device, reminiscent of a dental tool, slowly spins to
                        catch a glimpse of itself in an awkward machine-self portrait. Lastly, Stanza’s “The Agency at the end of Civilization (2014), is a massive array of networked cameras and screens that display real video links from CCTV cameras,
                        which watch UK car number plates; out of these visions the machine creates narratives and stories that distort our perception of what is real, and what is speculative.</p>

                    <p>Jo Shin’s project, “You.got.a.pic?” addresses the question of machine vision and self-imagination, and draws upon themes of immediacy in a hyper-mediated world. When sent a “seflie” image, the AI developed for this project responds
                        to an email with a modified “machine vision” version of this image – a distorted and pixelated view of the human in question. In the corresponding records in the zine, “Project Canary” imagines this process as a way to teach an
                        AI how to “see”; and gives a paper based lesson on pixel sorting – an analog experimentation of the digital process used in the “You.got.a.pic?” processing tool. As the correspondence between the AI and the human via email takes
                        time, Shin demands that we question our obsession with instantaneous communication and hypermediacy (Bolter and Grusin 1999). Likewise slowly sorting pixels by hand is the only way humans might begin to understand how these processing
                        components allow the computer to virtually “see” us.</p>

                    <p>Xavier Wu’s project, “Sentinel #002”, imagines an AI capable of recording and learning from human language. Instead of drawing upon written texts or carefully worded posts, this machine would collect data from social media sites like
                        Twitter. Language could be learnt from real time conversational and emotional utterances, not unlike recent AI advancements in Google Translate (Lewis-Kraus 2016). By analyzing these posts through key words, it would be possible
                        to calculate and enumerate the average emotional status of humans at any given time. By teaching an AI to attribute emotional values like “happiness” to certain words, sentences, and conversations, might we be able to teach it
                        something about the world and history? About the affectual relationships between people? The Sentinel #002 records included in the zine demonstrate what such a governmental project would be, the graphs created expose how a machine
                        might measure these relations with text-based processors.</p>

                    <p>“Human Memory Database,” by Frederico Machuca, presents an ominous vision of a future database of human memories. As the user clicks through the interface, text memories appear, with associated images flickering behind. The memories
                        are real; and the work allows us a glimpse into what might be machine-readable database of memories. What is at stake if such a system were real as well? How would we teach a machine to remember? The records of Human Memory Database
                        included in the zine addresses this question as a bureaucratic document: a machine-readable text entry field is provided for new memories to be added by hand.</p>

                    <p>The accompanying zine asks the viewer to imagine a world where media technologies as we know them have come and gone. In an era of reverse-bureaucratic “paper” knowledge work (Gitelman 2014); where an all seeing eye has gained intelligence,
                        human communications have become low-tech and actively evade the computer’s graphical screen and vision. The zine is provocation and a media archaeology (Huhtamo and Parikka 2011) artifact of the past from 3000 years in the future.
                        It imagines a world in which a typeface (ZXX) was developed to prevent machine surveillance and the optical character recognition of documents (Mun 2013). Picking up the zine in your hands, you are to imagine that you are now seeing
                        something you should not – and that you are also uniquely able to read the text that this future dystopian AI cannot. In this future, the humans are spying on the computer – not the other way around. Drawing on theoretical issues
                        of media and format specificity (Sterne 2012) and the role bureaucracy plays in the development and use media technologies (Eichhorn 2016); the zine is reminiscent of soon outdated media technologies: paper, the pen, the typewriter,
                        and the Xerox machine.</p>

                    <p>What is compelling about a cat robot that watches a fish? It is not the question of whether or not the cat sees the fish, but rather what it is that makes it frightening to imagine if this was the case. This imaginative future – and
                        the knowledge that the eye, for example, is not actually watching you – presents a dilemma. What if it was following you? Learning from you, repeating your actions, intentions, and emotions? Is that a future too frightening to
                        not be prepared for?</p>

                    <p>Witnessing was recently exhibited as part of the symposium, <a href="https://www.facebook.com/events/152700648576516/" target="_blank">“Under
                        Super Vision”</a> in the Art History, Visual, and Art Theory (AHVA) Department at the University of British Columbia (UBC) in the Audain Art Centre, curated by Laurie White, Sherena Razek, Whitney Brennan, and Paula Booker.</p>

                    <p><strong>– Hannah Turner, Vancouver 2017</strong></p>

                    <p><span>A note on the typeface: “The name ZXX comes from the Library of Congress' Alpha-3 ISO 639-2 -- codes
                        for the representation of names of languages. ZXX is used to declare No Linguistic Content; Not Applicable.” (Mun, 2012). ZXX is
                        a disruptive typeface developed by Sang Mun (www.sang-mun.com), a former contractor with the US National Security Agency (NSA) (Mun, 2013).
                        He designed the typeface as a way to “conceal our fundamental thoughts from artificial intelligences,” and the typeface itself is unreadable
                        by text scanning software. As Mun notes, ZXX is intended to raise questions about privacy and the protection and codification of human
                        emotions, thoughts, and affective experiences. It is a censor for humanity in the information age.</span></p>

                    <h3>References and Further Reading</h3>
                    <ul>
                        <li>Ansendorf, Kim. 2012. ASDFPixelSort. [Open source code]. GitHub. Online: https://github.com/kimasendorf/ASDFPixelSort. Accessed November 1, 2016</li>
                        <li>Basanta, Adam. 2016. A Truly Magical Moment [2 cell phones, 2 cell phone sticks, electronics, speaker, rotating motor]. Displayed at the “Witness” exhibit, Curated by Sarah Joyce and Gordon Duggan at the New Media Gallery, New
                            Westminster, BC, September 8th – November 6th 2016.</li>
                        <li>Bolter, J. David, and Richard Grusin. 1999. Remediation: Understanding New Media. Cambridge, MA: MIT Press.</li>
                        <li>Cadet, France. 2007. Do Robotic Cats Dream of Electric Fish? [Robotic Cat (altered), Plinth, Flat Screen, Digital Files, Plastic, Batteries, Rubber, LEDs, Circuit boards and chips]. Displayed at the “Witness” exhibit, Curated by
                            Sarah Joyce and Gordon Duggan at the New Media Gallery, New Westminster, BC, September 8th – November 6th 2016.</li>
                        <li>Cubitt, Sean. 2014. The Practice of Light: A Genealogy of Visual Technologies from Prints to Pixels. Cambridge, MA: MIT Press.</li>
                        <li>Ansendorf, Kim. 2012. ASDFPixelSort. [Open source code]. GitHub. Online: https://github.com/kimasendorf/ASDFPixelSort. Accessed November 1, 2016</li>
                        <li>Basanta, Adam. 2016. A Truly Magical Moment [2 cell phones, 2 cell phone sticks, electronics, speaker, rotating motor]. Displayed at the “Witness” exhibit, Curated by Sarah Joyce and Gordon Duggan at the New Media Gallery, New
                            Westminster, BC, September 8th – November 6th 2016.</li>
                        <li>Bolter, J. David, and Richard Grusin. 1999. Remediation: Understanding New Media. Cambridge, MA: MIT Press.</li>
                        <li>Cadet, France. 2007. Do Robotic Cats Dream of Electric Fish? [Robotic Cat (altered), Plinth, Flat Screen, Digital Files, Plastic, Batteries, Rubber, LEDs, Circuit boards and chips]. Displayed at the “Witness” exhibit, Curated by
                            Sarah Joyce and Gordon Duggan at the New Media Gallery, New Westminster, BC, September 8th – November 6th 2016.</li>
                        <li>Cubitt, Sean. 2014. The Practice of Light: A Genealogy of Visual Technologies from Prints to Pixels. Cambridge, MA: MIT Press.</li>
                        <li>Davies, E. R. 2004. Machine Vision: Theory, Algorithms, Practicalities. San Francisco: Morgan Kaufmann.</li>
                        <li>Drucker, Johanna. 2014. Graphesis: Visual Forms of Knowledge Production. Cambridge, MA: Harvard University Press.</li>
                        <li>Eichhorn, Kate. 2016. Adjusted Margin: Xerography, Art, and Activism in the Late Twentieth Century. London; Cambridge, MA: MIT Press.</li>
                        <li>Gitelman, Lisa. 2014. Paper knowledge: Toward a Media History of Documents. Durham; London: Duke University Press.</li>
                        <li>Hayles, Katherine. 1999. How We Became Posthuman: Virtual Bodies in Cybernetics, Literarture and Informatics. Chicago: University of Chicago Press.</li>
                        <li>Hertz, Garnet and Jussi Parikka. 2011. “Appendix: Zombie Media, Circuit Bending Media Archaeology into an Art Method.” In A Geology of Media, by Jussi Parikka. Minneapolis; London: University of Minnesota Press.</li>
                        <li>Huhtamo, Erkki, and Jussi Parikka, eds. 2011. Media Archaeology Approaches, Applications, and Implications. Berkeley: University of California Press.</li>
                        <li>Joyce, Sarah, and Gordon Duggan. 2016. Witness. New Media Gallery, New Westminster, BC, September 8th – November 6th 2016. Online: http://newmediagallery.ca/current-exhibition-2/. Accessed October 25 2016.</li>
                        <li>Kelley, Michael. 2013. "Designer Creates New Anti-Snooping Font That Google Can't Read." Business Insider. September 27. Online: http://www.businessinsider.com/zxx-fonts-that-google-cant-read-2013-9. Accessed: December 8, 2016.</li>
                        <li>Kinder, Marsha and Tara McPherson, eds. 2014. Transmedia Frictions: The Digital, the Arts, and the Humanities. Berkeley: UC Press.</li>
                        <li>Krikorian, Raffi. 2013. “New Tweets per second record, and how!” Twitter Blogs. Online: https://blog.twitter.com/2013/new-tweets-per-second-record-and-how. Accessed January 25, 2016.</li>
                        <li>Kwastek, Kaja. 2013. Aesthetics of Interaction in Digital Art. Cambridge, MA: MIT Press.</li>
                        <li>Lewis-Kraus, Gideon. 2016. "The Great A.I. Awakening. How Google used artificial intelligence to transform Google Translate, one of its more popular services — and how machine learning is poised to reinvent computing itself." Online:
                            https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?_r=1. Accessed December 28, 2016.</li>
                        <li>Lozano-Hemmer, R., 1992 (2001). Surface Tension [Infra Red Light, Infra Red Camera, Mac Mini, 65" LCD Monitor]. Displayed at the “Witness” exhibit, Curated by Sarah Joyce and Gordon Duggan at the New Media Gallery, New Westminster,
                            BC, September 8th – November 6, 2016.</li>
                        <li>Manovich, Lev. 2002. The Language of New Media. Cambridge, MA: MIT Press.</li>
                        <li>Mun, Sang. 2013. “Making Democracy Legible: A Defiant Typeface.” Walker Art Centre Blog. Online: http://blogs.walkerart.org/design/2013/06/20/sang-mun-defiant-typeface-nsa-privacy. Accessed November 1, 2016. 2012. ZXX [Digital
                            Typeface and Readme File]. Online: http://www.sangmun.com/ZXX. Accessed November 1, 2016.</li>
                        <li>Parikka, Jussi. 2012. What is Media Archaeology? Cambridge, UK; Malden, MA: Polity Press.</li>
                        <li>Paul, Christiane. 2006. “The Myth of Immateriality: Presenting and Preserving New Media” in Media Art Histories edited by Oliver Grau. Cambridge, MA: MIT Press.</li>
                        <li>Ravetto-Biagioli, Kriss. 2010. "Shadowed by Images: Rafael Lozano-Hemmer and the Art of Surveillance." Representations 111.1: 121-43.</li>
                        <li>Schülke, Björn. 2014. Vision Machine [Wood, brass, steel, camera, screen display, paint, sensor, LED, belt drive, custom electronics, motor, mirrors]. Witness exhibit at New Media Gallery, New Westminster, BC.</li>
                        <li>Shiffman, Daniel, Ben Fry and Casey Reas. 2008. Edge Detection. [Code] Processing.org. Accessed November 1, 2016.</li>
                        <li>STANZA. 2014. The Agency at the End of Civilization. [22 screens, 36 dome CCTV, 3 NUC PC, 1 Mini Mac,3 VGA splitters, Ethernet hub, 1 Motu sound card, 2 Custom made amps, Loads of tubes and load of power supplies and cables, 1
                            figure 3d portrait scan, 8 hi end mini speakers]. Witness exhibit at New Media Gallery, New Westminster, BC.</li>
                        <li>Sterne, Jonathan. 2012. MP3: the Meaning of a Format. Durham: Duke University Press.</li>
                        <li>Vinson, Kevin D., and E. Wayne Ross. 2001. "Education and the New Disciplinarity: Surveillance, Spectacle, and the Case of SBER." Cultural Logic. 4(1). Online: http://clogic.eserver.org/4-1/vinson%26ross.html. Accessed January
                            14, 2017.</li>
                        <li>Zielinski, Siegfried. 2006. Deep Time of the Media: Toward an Archaeology of Hearing and Seeing by Technical Means. Cambridge, MA: MIT Press.</li>
                    </ul>
                </div>
            </div>
            <!-- Credits -->
            <div class="icon glitch example-three">
                <a class="readme-icon credits-txt" href="#" data-featherlight="#credits-lightbox" data-featherlight-variant="custom-lightbox glitch-child glitch-child-1">credits.txt</a>
                <div class="hidden-lightbox lightbox-content" id="credits-lightbox">
                    <h2>- Credits -</h2>
                    <p>The <a href="http://criticalmediartstudio.com/" target="_blank">criticalmediartstudio</a> (cMAS) explores how old and new technologies have and continue to shape historical narratives and practices of media arts and design.
                        Our research outputs can take the shape of an art exhibition; a scholarly publication; a public performance; an experimental video; a generative artwork;  an interactive digital graphic novel; a printed zine or an artist book.
                        Located in the <a href="http://www.sfu.ca/siat.html" target="_blank">School of Interactive Arts and Technology</a> at Simon Fraser University Surrey Campus, cMAS is directed by Dr. Gabriela Aceves Sepulveda.</p>

                    <h3>cMAS collective members</h3>
                    <ul>
                        <li>Gabriela Aceves Sepulveda, Assistant Professor, Critical Media Arts Studio (cMAS), School of Interactive Art and Technology (SIAT) at Simon Fraser University.<br>
                            <script language="JavaScript">
                            var username = "gaceves"; var hostname = "sfu.ca"; var linktext = username + "@" + hostname ; document.write("<a href='" + "mail" + "to:" + username + "@" + hostname + "'>" + linktext + "</a>");
                            </script></li>
                        <li>Hannah Turner, Postdoctoral Fellow, Making Culture Lab, School of Interactive Art and Technology (SIAT) at Simon Fraser University.<br>
                            <script language="JavaScript">
                            var username = "hannah_turner"; var hostname = "sfu.ca"; var linktext = username + "@" + hostname ; document.write("<a href='" + "mail" + "to:" + username + "@" + hostname + "'>" + linktext + "</a>");
                            </script></li>
                        <li>Jo Shin, Critical Media Arts Studio (cMAS), School of Interactive Art and Technology (SIAT) at Simon Fraser University.<br>
                            <script language="JavaScript">
                            var username = "jo_shin"; var hostname = "sfu.ca"; var linktext = username + "@" + hostname ; document.write("<a href='" + "mail" + "to:" + username + "@" + hostname + "'>" + linktext + "</a>");
                            </script></li>
                        <li>Frederico Machuca, Critical Media Arts Studio (cMAS), School of Interactive Art and Technology (SIAT) at Simon Fraser University.<br>
                            <script language="JavaScript">
                            var username = "Fmachuca"; var hostname = "sfu.ca"; var linktext = username + "@" + hostname ; document.write("<a href='" + "mail" + "to:" + username + "@" + hostname + "'>" + linktext + "</a>");
                            </script></li>
                        <li>Xavier Wu, Critical Media Arts Studio (cMAS), School of Interactive Art and Technology (SIAT) at Simon Fraser University.<br>
                            <script language="JavaScript">
                            var username = "Xavierw"; var hostname = "sfu.ca"; var linktext = username + "@" + hostname ; document.write("<a href='" + "mail" + "to:" + username + "@" + hostname + "'>" + linktext + "</a>");
                            </script></li>
                    </ul>
                </div>
            </div>
            <!-- Zine Download -->
            <div class="icon glitch example-three">
                <a class="readme-icon witnessing-icon" href="witnessing_zine.pdf" target="_blank" data-featherlight-variant="custom-lightbox glitch-child glitch-child-1">zine_full.pdf</a>
            </div>
        </inner-container>
    </outer-container>
    <footer>
        <h1></h1>
    </footer>
    <!-- Featherlight Box -->
    <script src="https://code.jquery.com/jquery-latest.js"></script>
    <script src="featherlight.js"></script>
</body>

</html>
